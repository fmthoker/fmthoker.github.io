<!DOCTYPE html>

<html>

  <head>
      <script async src="https://www.googletagmanager.com/gtag/js?id=UA-116924853-1"></script>
      <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'UA-116924853-1');
          </script>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">

<title>Fida Mohammad Thoker</title>
<meta name="description" content="">

<link rel="stylesheet" href="css/main.css">
<link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css"/>
<link rel="shortcut icon" type="image/ico" href="favicon.ico" />		

    <!-- Custom fonts for this template -->
    <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:100,200,300,400,500,600,700,800,900" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i,800,800i" rel="stylesheet">
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet">
    <link href="vendor/devicons/css/devicons.min.css" rel="stylesheet">
    <link href="vendor/simple-line-icons/css/simple-line-icons.css" rel="stylesheet">
	

<link rel='stylesheet' id='open-sans-css'  href='//fonts.googleapis.com/css?family=Open+Sans%3A300italic%2C400italic%2C600italic%2C300%2C400%2C600&#038;subset=latin%2Clatin-ext&#038;ver=4.2.4' type='text/css' media='all' />
<link href='https://fonts.googleapis.com/css?family=Titillium+Web:600italic,600,400,400italic' rel='stylesheet' type='text/css'>

<!-- fontawesome and academicons -->
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/all.css" integrity="sha384-lKuwvrZot6UHsBSfcMvOkWwlCMgc0TaWr+30HWe3a4ltaBwTZhyTEggF5tJv8tbt" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">




</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Fida Mohammad Thoker</a>


    <nav class="site-nav">

      <a href="#" class="menu-icon menu.open">
        <svg viewBox="0 0 18 15">
          <path fill="#4CAC9D" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#4CAC9D" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#4CAC9D" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>  

    <div class="trigger"><h1>Main Navigation</h1>

 <ul class="menu">

    
    
    
    </ul>


     </div>  
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <p><img src="img/profile.jpg" style="width: 180px; float: right" hspace="20" /></p>

        <p> I am postdoctoral researcher at <strong> <a href="https://www.kaust.edu.sa/en/">King Abdullah University of Science and Technology (KAUST)</a> </strong> working with  <a href="https://www.bernardghanem.com/">Prof. Bernard Ghanem</a>. I completed my Phd at the <a href="https://www.uva.nl/en?cb">University of Amsterdam</a>, advised by <a href="http://www.ceessnoek.info/">Prof. Cees Snoek</a>. My area of interest is Video Understanding, with my PhD thesis (which you can find <strong> <a href="pdfs/colored_digital_thesis_final.pdf">here</a> </strong>) focussing on Video-Efficient Foundation Models. I am particularly interested in training foundation models via self-supervised learning from multiple modalities of the video data. </p>

<!-- Icons from fontawesome (Make less ugly later) -->
<ul class="list-inline list-social-icons mb-0">

              <li class="list-inline-item">
                  <a href="https://scholar.google.com/citations?user=vqN8M3MAAAAJ&hl=en">
                      <span class="fa-stack fa-lg">
                          <i class="ai ai-google-scholar-square ai-2x"></i>
                      </span>
                  </a>
              </li>

              <li class="list-inline-item">
                  <a href="https://github.com/fmthoker">
                      <span class="fa-stack fa-lg">
                          <i class="fa fa-square fa-stack-2x"></i>
                          <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                      </span>
                  </a>
              </li>

              <li class="list-inline-item">
                  <a href="https://twitter.com/fmthoker">
                      <span class="fa-stack fa-lg">
                          <i class="fa fa-square fa-stack-2x"></i>
                          <i class="fab fa-twitter fa-stack-1x fa-inverse"></i>
                      </span>
                  </a>
              </li>
              <li class="list-inline-item">
                  <a href="https://www.linkedin.com/in/fmthoker/">
                      <span class="fa-stack fa-lg">
                          <i class="fa fa-square fa-stack-2x"></i>
                          <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                      </span>
                  </a>
              </li>

              <li class="list-inline-item">
                  <a href="CV.pdf">
                      <span class="fa-stack fa-lg">
                          <i class="fa fa-square fa-stack-2x"></i>
                          <i class="fa fa-id-card fa-stack-1x fa-inverse"></i>
                      </span>
                  </a>
              </li>
</ul>
<p><strong>Contact</strong>: f.m.thoker *at* uva.nl<br />
<h1 id="news--activities">News &amp; Activities</h1>
<hr />

<div class="container"> <div class="events">
    <ul>
        <li> September 2024: Our paper <a href="">'LocoMotion: Learning Motion-Focused Video-Language Representations'</a> is accepted as an Oral to ACCV
        <li> July 2024: Our paper <a href="https://arxiv.org/abs/2407.15447">'SIGMA: Sinkhorn-Guided Masked Video Modeling'</a> is accepted to ECCV
        <li> May 2024: I gave a talk at <strong> <a href="https://skatingverse.github.io/">SkatingVerse Workshop </a> </strong>, <a href="https://fg2024.ieee-biometrics.org/">International Conference on Automatic Face and Gesture Recognition 2024 </a> </strong>

        <li> March 2024: I joined  joined <strong> <a href="https://www.kaust.edu.sa/en/">King Abdullah University of Science and Technology (KAUST)</a> </strong> as a Post Doctoral Researcher
         <li> December 2023: I successfully defended my Ph.D. thesis titled <strong> <a href="https://dare.uva.nl/search?identifier=89efbea4-62f5-426f-8208-5ba91948ecf4">Video-Efficient Foundation Models</a> </strong>
        <li> November 2023: My <strong> <a href="pdfs/colored_digital_thesis_final.pdf">Ph.D. thesis </a> </strong> is approved by the doctoral committee, with defense set on 8th of December 2023
        <li> September 2023: <a href="https://arxiv.org/abs/2303.11003">'Tubelet-Contrastive Self-Supervision for Video-Efficient Generalization'</a> is accepted as an oral at NCCV
        <li> August 2023: I gave a talk at  University of Bonn. Thanks for the invitation from JÃ¼rgen Gall </a> 
        <li> August 2023: I am selected for <a href="https://iccv2023.thecvf.com/call.for.participation-363200-2-30-32.php">'ICCV 2023 Doctoral Consortium'</a> 
        <li> July 2023: Our paper <a href="https://arxiv.org/abs/2303.11003">'Tubelet-Contrastive Self-Supervision for Video-Efficient Generalization'</a> is accepted to ICCV
        <li> April 2023: I gave a talk at  King Abdullah University of Science and Technology (KAUST). Thanks for the invitation from Bernard Ghanem </a> 
        <li> August 2022: I attented  <a href="https://iplab.dmi.unict.it/icvss2022/">International Computer Vision Summer School (ICVSS)</a> 2022
        <li> July 2022: Our paper <a href="https://arxiv.org/abs/2203.14221">'How Severe is Benchmark-Sensitivity in Video Self-Supervised Learning?'</a> is accepted to ECCV
        <li> August 2021: Our paper <a href="https://arxiv.org/abs/2108.03656">Skeleton-Contrastive 3D Action Representation Learning</a> was accepted at ACM Multimedia
        <li> Octobre 2020: Our paper <a href="https://arxiv.org/abs/2108.03329">Feature-Supervised Action Modality Transfer</a> was accepted at ICPR
        <li> May 2019: I joined <a href="https://ivi.fnwi.uva.nl/vislab/"> VIS LAB </a> as a Ph.D. candidate at <a href="https://www.uva.nl/"> Univeristy of Amsterdam </a>
        <li> April 2019: Our paper <a href="https://arxiv.org/abs/1910.04641">CROSS-MODAL KNOWLEDGE DISTILLATION FOR ACTION RECOGNITION</a> was accepted at ICIP
    </ul>
  </div></div>
<h1 id="publications">Publications</h1>
<hr />

<table class="researchtable">

<tbody>

    <tr>
        <td class="img"> <img src="img/tubelet_teaser.png" /> </td>
        <td valign="top">
            <strong>SIGMA: Sinkhorn-Guided Masked Video Modeling</strong><br />
            Mohammadreza Salehi*, Michael Dorkenwald*, <u>Fida Mohammad Thoker*</u>, Efstratios Gavves, Cees G. M. Snoek, Yuki M. Asano<br />
            European Conference on Computer Vision (<strong>ECCV</strong>), 2024. <br />
            <strong><a href="">[Webpage]</a>
            <a href="https://arxiv.org/abs/2407.15447">[arXiv]</a>
            <a href="https://github.com/QUVA-Lab/SIGMA">[Code]</a></strong>

        </td>
    </tr>

    <tr>
        <td class="img"> <img src="img/tubelet_teaser.png" /> </td>
        <td valign="top">
            <strong>Tubelet-Contrastive Self-Supervision for Video-Efficient Generalization</strong><br />
            <u>Fida Mohammad Thoker</u>, Hazel Doughty,  Cees Snoek<br />
            International Conference on Computer Vision (<strong>ICCV</strong>), 2023. <br />
            <strong><a href="https://fmthoker.github.io/tubelet-contrastive-learning/">[Webpage]</a>
            <a href="https://arxiv.org/abs/2303.11003">[arXiv]</a>
            <a href="https://github.com/fmthoker/tubelet-contrast">[Code]</a></strong>

        </td>
    </tr>

    <tr>
        <td class="img"> <img src="img/BenchmarkTeaser.png" /> </td>
        <td valign="top">
            <strong>How Severe is Benchmark-Sensitivity in Video Self-Supervised Learning?</strong><br />
            <u>Fida Mohammad Thoker</u>, Hazel Doughty, Piyush Bagad, Cees Snoek<br />
            European Conference on Computer Vision (<strong>ECCV</strong>), 2022. <br />
            <strong><a href="https://bpiyush.github.io/SEVERE-website/">[Webpage]</a> <a href="https://arxiv.org/abs/2203.14221">[arXiv]</a> <a href="https://github.com/fmthoker/SEVERE-BENCHMARK">[Code]</a></strong>
        </td>
    </tr>

    <tr>
        <td class="img"> <img src="img/skeleton_contrast.png" /> </td>
        <td valign="top">
            <strong>Skeleton-Contrastive 3D Action Representation Learning</strong><br />
            <u>Fida Mohammad Thoker</u>, Hazel Doughty, Cees Snoek<br />
            ACM International Conference on Multimedia (<strong>ACMMM</strong>), 2021<br />
            <strong> <a href="https://arxiv.org/abs/2108.03656">[arXiv]</a> <a href="https://github.com/fmthoker/skeleton-contrast">[Code]</a></strong>
        </td>
    </tr>

    <tr>
        <td class="img"> <img src="img/feature-supervised.png" /> </td>
        <td valign="top">
            <strong>Feature-Supervised Action Modality Transfer</strong><br />
            <u>Fida Mohammad Thoker</u>, Cees Snoek<br />
            IEEE International Conference on Pattern Recognition (<strong>ICPR</strong>), 2020<br />
            <strong> <a href="https://arxiv.org/abs/2108.03329">[arXiv]</a> </strong>
        </td>
    </tr>

    <tr>
        <td class="img"> <img src="img/cross-modal.png" /> </td>
        <td valign="top">
            <strong>CROSS-MODAL KNOWLEDGE DISTILLATION FOR ACTION RECOGNITION</strong><br />
            <u>Fida Mohammad Thoker</u>, Juergen Gall<br />
            IEEE International Conference on Image Processing (<strong>ICIP</strong>), 2019<br />
            <strong> <a href="https://arxiv.org/abs/1910.04641">[arXiv]</a> </strong>
        </td>
    </tr>

</tbody>
</table>
<br>
<h1 id="misc" style="padding-top: 10px">Academic Service</h1>
<hr />
<br>
Reviewer: BMVC 2020, CVIU 2021, Nuerips 2021, ICCV 2021, ECCV 2022, ACCV 2022, CVPR 2023, ICCV 2023
<br>

<br>
<h1 id="teaching" style="padding-top: 20px">Teaching</h1>
<hr />
<br>
Teaching Assistant: Deep Learning for Visual Recognition (MSc Computer Science Univerisity of Bonn)
<br>
Teaching Assistant: Technical Neural Networks (MSc Computer Science Univerisity of Bonn)

      </div>
    </div>

    <footer class="site-footer">



</footer>

  </body>

</html>
